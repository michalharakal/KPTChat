= Transformers

Transformers ist eine Architektur für tiefe neuronale Netze, die von Google entwickelt wurde. Sie wurde 2017 in dem Paper https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbS14cjNteG45S2xmZnlWOHVtNGZNXzhTRW1KZ3xBQ3Jtc0tsTjhPMTRaYXVKWFQ3MWlPcnladEhKczVPTzR6SWdMdmttRUd0RldhVVpLdGhXY1BPdjQwTkVZdHdrYnhodEdIVXZVMTJucGxEdnNtZjJON3g0dG5qZ1JhNElLQjRYTFhSdEtFYnNPQ2N3TldVRWlBVQ&q=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762&v=kCc8FmEb1nY["Attention is All You Need"] vorgestellt und hat seitdem viele Anwendungsbereiche revolutioniert. Transformer-Netze sind in der Lage, lange Abhängigkeiten in Sequenzen zu modellieren und haben viele klassische Architekturen wie RNNs und LSTMs in der Verarbeitung natürlicher Sprache abgelöst.