= Sources und Links

https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbS14cjNteG45S2xmZnlWOHVtNGZNXzhTRW1KZ3xBQ3Jtc0tsTjhPMTRaYXVKWFQ3MWlPcnladEhKczVPTzR6SWdMdmttRUd0RldhVVpLdGhXY1BPdjQwTkVZdHdrYnhodEdIVXZVMTJucGxEdnNtZjJON3g0dG5qZ1JhNElLQjRYTFhSdEtFYnNPQ2N3TldVRWlBVQ&q=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762&v=kCc8FmEb1nY[Attention is All You Need Paper]


== Bilder

=== Transformer Architektur
* Tranformer Architektur Bild https://www.mdpi.com/biology/biology-12-01033/article_deploy/html/images/biology-12-01033-g001.png

Choi, S.R.; Lee, M. Transformer Architecture and Attention Mechanisms in Genome Data Analysis: A Comprehensive Review. Biology 2023, 12, 1033. https://doi.org/10.3390/biology12071033